from typing import Set, List
import warnings
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import CommaSeparatedListOutputParser

class QueryClassifier:
    """Classifies queries to determine appropriate search environment."""
    
    WEB_KEYWORDS: Set[str] = {
        "current", "latest", "real-time", "recent", "today",
        "news", "update", "live", "trending", "market",
        "price", "weather", "stock", "social media"
    }
    
    def __init__(self, model_name: str = "gpt-4-turbo-preview"):
        """Initialize classifier with OpenAI model."""
        self.llm = ChatOpenAI(model=model_name)
        self.parser = CommaSeparatedListOutputParser()
        
        # Configure classification prompt
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """Classify if the task requires real-web search (Perplexity) or can be handled in closed environment (OpenAI). Use:
            - 'web' if needing current/live data, real-world updates, or external verification
            - 'closed' for theoretical, general knowledge, or code-related tasks"""),
            ("human", "Task: {task}\nClassification:")
        ])
        
        self.chain = self.prompt | self.llm | self.parser
    
    def classify(self, query: str) -> str:
        """
        Determine if query needs web search or closed environment.
        
        Args:
            query: The task/query to classify
            
        Returns:
            str: Either 'web' or 'closed'
        """
        try:
            # First try fast keyword matching
            if any(kw in query.lower() for kw in self.WEB_KEYWORDS):
                return "web"
            
            # Fallback to LLM classification
            classification = self.chain.invoke({
                "task": query
            })[0].strip().lower()
            
            return classification if classification in ["closed", "web"] else "closed"
            
        except Exception as e:
            warnings.warn(f"Search classification failed: {str(e)}")
            return "closed"  # Safe default

def compute_perplexity(query: str) -> float:
    """
    Compute a simulated perplexity score for a given decomposed subquery.
    
    In a production environment, this function would compute perplexity using the
    language model's log-likelihood estimates. For this mock implementation, we use 
    a simple heuristic:
      - Base perplexity is set to 20.
      - Each word in the query adds 0.5 to the perplexity.
      
    Parameters:
        query (str): The decomposed subquery string.
        
    Returns:
        float: The computed perplexity score.
    """
    base_perplexity = 20.0
    additional_perplexity = len(query.split()) * 0.5
    return base_perplexity + additional_perplexity

def label_subquery_environment(subquery: str, perplexity_threshold: float = 30.0) -> str:
    """
    Labels a decomposed subquery based on its computed perplexity, indicating the 
    appropriate search environment.
    
    The function assesses whether a subquery generated by the agentController should 
    be handled within the closed OpenAI (ChatGPT) environment or if it requires a 
    real-web search. A subquery with a perplexity score above the threshold is labeled 
    as "open_environment" (i.e., it needs real-web perplexity search), while those with 
    lower scores are labeled as "closed_environment" (handled within ChatGPT).
    
    Parameters:
        subquery (str): The decomposed subquery string.
        perplexity_threshold (float): The threshold perplexity above which the subquery 
                                      should be labeled for open web search. Default is 30.0.
        
    Returns:
        str: Either "closed_environment" or "open_environment".
    """
    perplexity = compute_perplexity(subquery)
    if perplexity > perplexity_threshold:
        return "open_environment"
    else:
        return "closed_environment"

if __name__ == "__main__":
    # Example decomposed subqueries generated by the agentController
    subquery1 = "code_generation: Generate a function to sort an array using merge sort"
    subquery2 = (
        "data_analysis: Analyze market trends in renewable energy, including historical data, "
        "future projections, socio-economic factors, and geopolitical influences over the next decade."
    )
    
    # Label each subquery with the corresponding search environment
    label1 = label_subquery_environment(subquery1)
    label2 = label_subquery_environment(subquery2)
    
    print(f"Subquery 1 is labeled for: {label1}")
    print(f"Subquery 2 is labeled for: {label2}")
